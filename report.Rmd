---
title: "Classification of titanic data"
author: "Vladislav Brion"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
  
---


```{r libs, include = FALSE}

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(tidyverse)

library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(ROCR)
library(caret)
library(randomForest)
library(fastDummies)
library(adabag)
library(kableExtra)

```

```{r Read and transform, echo = FALSE}

titanic <- read_csv("data/titanic3.csv")

misRows <- apply(!is.na(titanic), 1, sum)
titanic <- titanic %>% filter(misRows != 0) %>% as_tibble %>% 
    dplyr::select(-c("name", "ticket", "boat", "body", "home.dest")) %>% 
    mutate(cabinFirstLetter = str_sub(cabin, end = 1)) %>% dplyr::select(-cabin)


tab1 <- as.tibble(colSums(is.na(titanic)))
tab2 <- count(titanic, pclass, cabinFirstLetter)
tab3 <- count(titanic %>% filter(pclass == 1), pclass, cabinFirstLetter, survived)

fare0 <- sum(titanic$fare < 0.01, na.rm = T)

titanic <- titanic %>% 
  mutate(pclassCab = case_when(pclass %in% c(2, 3) ~ as.character(pclass),
                              is.na(cabinFirstLetter) |  cabinFirstLetter %in% c("A", "T") ~ paste(pclass, "Other", sep = ""),
                              TRUE                                        ~ "pclassBCDE")) %>% 
  dplyr::select(-cabinFirstLetter) %>% 
  mutate(fare = ifelse(is.na(fare), 0.0, fare)) # correct 1 record for further imputation

fareClass <- titanic %>% filter(fare > 0) %>% group_by(pclass) %>% summarize(fare123 = median(fare))
titanic <- titanic %>% inner_join(fareClass) %>% 
  mutate(fare = ifelse(fare < 0.01, fare123, fare)) %>% dplyr::select(-fare123) %>% 
  mutate(fare = log(fare))

titanic <- titanic %>%mutate_at(c("age", "sibsp", "parch"), as.integer) %>% 
  mutate_at(c("survived", "pclass", "sex", "pclassCab", "embarked"), as.factor)

nSurv <- round(100 * sum(titanic$survived == 1) / nrow(titanic), 2)

cortab <- as.tibble(cor(titanic %>% dplyr::select(age, sibsp, parch, fare), method="pearson", use="pairwise.complete.obs")) %>% mutate_all(function(x) { ifelse(x == 1.0, 0, x)})
maxCorr <- round(max(abs(cortab)), 2)

```

This report contains results of applying various supervised learning methods to titanic data. Quality of survival outcome predictions is outlined.

### The data

The original titanic dataset contains `r nrow(titanic)` observations and `r ncol(titanic)` columns. One record without non-missing values was removed. The survived binary variable (0 - not survived; `r 100 - nSurv`% observations, and 1 - survived; `r nSurv`% observations) is used as an outcome for all models, whereas other variables can be considered as candidates for predictors. The name, ticket, boat, body, home.dest variables shouldn't have impact on the surviving a person, and were permanently removed from the analysis. 

The cabin variable is replaced by cabinFirstLetter variable consisting of the first letter of the cabin. This letter can contain additional information about class or location of a cabin.

Table 1 shows number of missing values in the dataset.

```{r tab1, echo = FALSE}

knitr::kable(tab1, caption = "Table 1. Counts of missing values") %>% kable_styling(bootstrap_options = c("striped", "hover"))

```

The cabinFirstLetter variable has `r tab1[["cabinFirstLetter"]]` missig records. This number is large, and this variable can't be efficiently used without imputation. This variable can be used together with the pclass variable, as shown on the table below.

```{r tab2, echo = FALSE}

knitr::kable(tab2, caption = "Table 2. Counts of pclass and cabin factors") %>% kable_styling(bootstrap_options = c("striped", "hover"))

```

This variable can't be used for splitting levels pclass = 2 or 3 due to majority of its missing values. On the other side, the level pclass = 1 can be possibly split on multiple levels depending on the cabinFirstLetter values. I don't want to split it onto many levels with non-frequent counts. The split can be performed using thetable below:

```{r tab3, echo = FALSE}

knitr::kable(tab3, caption = "Table 3.  Counts of pclass = 1, cabin and survived factors") %>% kable_styling(bootstrap_options = c("striped", "hover"))

```

The pclass = 1 can be split onto 2 levels: one belonging to the cabin values equal to B, C, D and  E (where the number of survived persons is much higher than the number of non-survived persons), and another one belonging to the missing cabin values, E and T (where the counts of both survived groups are close each other). In addition to the pclass predictor, I added the modified cabinFirstLetter variable to the possible list of predictors. At least one of them shouls be removed at stepwise step.


The fare variable contains `r fare0` zero records which were considered as incorrect and one missing record. I imputed them using the average fare for corresponding pclass. Also, logarithmic transformation was applied to the fare variable. This transformation could not affect on tree methods, but could improve the logistic regression.

The age variable contains `r sum(is.na(titanic$age))` missing records. It is relatively large number, and imputation of these missing values were not part of this report. The following two models can be considered:

1. Model containing the age variable. Some models won't consider the missing records, that cause to lower number of observations, and, as a result, reduced quality of the analysis.

2. The age variable is excluded from the model. This model will contain more records. However, the age variable may be important predictor. As a result, omitting this variable would also decrease the quality of analysis.

I started my analysis from the first model which is more general. As for other predictors, keeping the age predictor will be analysed during finding the best set of predictors for logistic regression.

Two missing embarkedvalues records won't impact on the model.

The numerical predictors aren't highly correlated. Their maximum pairwise correlation coefficient is `r maxCorr`. However, multicollinearity in the model can exist.

```{r stepwise, echo = FALSE}

titanic <- as.tibble(cbind(titanic %>% dplyr::select(survived), titanic %>% dplyr::select(-survived)))
titanicStep <- titanic
maxiter <- ncol(titanicStep) - 1
for(iter in 1 : maxiter)
{
  glmVarFull <- glm(survived ~ ., data = titanicStep, family = binomial(link = "logit"), na.action = na.exclude)
  if(iter == 1)
    AICfull <- round(summary(glmVarFull)$aic, 1)
  
  compTable <- as.data.frame(matrix(nrow = ncol(titanicStep), ncol = 3))
  names(compTable) <- c("rmVar", "Pval", "AIC")
  sumFull <- summary(glmVarFull)
  compTable$rmVar <- c("None", names(titanicStep[, -1]))
  compTable$AIC[1] <- sumFull$aic
  for(j in 2 : ncol(titanicStep)) # remove one var
  {
    glmVarRed <- glm(survived ~ ., data = titanicStep[, -j], family = binomial(link = "logit"), na.action = na.exclude)
    sumRed <- summary(glmVarRed)
    compTable$AIC[j] <- sumRed$aic
    rows <- str_which(row.names(sumFull$coefficients), names(titanicStep)[j])
    compTable$Pval[j] <- round(min(sumFull$coefficients[rows, 4]), 3) 
  }
  compTable <- compTable %>% arrange(AIC)
  rmVar <- compTable$rmVar[1]
  if(rmVar == "None")
    break
  
  titanicStep <- titanicStep %>% dplyr::select(-rmVar)
}
AICred <- compTable$AIC[1]
varSet <- compTable$rmVar[-1]

```

For logistic regression, the transformation log(x + 1) was applied to the sibsp and parch variables. In order to find the optimal set of predictors and reduce possible overfitting, I used the stepwise logistic regtression. Due to low number of possible predictors, the full model run very fast, and the backward approach was selected. Starting from the full model, I reduced each single predictor and select the current best model based on an  information criteria. 

Coefficients of the logistic regression correspond to maximum vlaue of likelihood function. Then, a low value of residual deviance which is proportional to negative log-likelihood value corresponds to a good fit. However, adding more predictors will always improve a fit. Then, larger number of predictors should be penalized. The Akaike information criteria (AIC) is the sum of the residual deviance and the double number of predictors. As a result, adding predictors which do not significantly improve the fit can make the model worse. For a single iteration of the backward stepwise regression, a predictor is selected to be removed when the corresponding model has the lowest AIC value. The itertation process of removing a single variable continues until the full model at current iteration is the best. In other words, further omitting of any predictor increases the AIC.

As a result, the model with full set of predictors having AIC = `r AICfull` was improved by reduced model with `r length(varSet)` predictors: `r varSet ` having AIC = `r round(AICred, 1)`. The age predictor remained in the model. Then, the best model contains the age predictor and has reduced number of observations. Also, the artificial cabinFirstLetter predictor was omitted.

## Classification methods

The current version of report considers the following classification methods:

- Logistic regression


For applying each classification method, the dataset was randomly split on training set (80% of observations) which was used for creating a predictor, and on testing set (20% of observations) which was used for quality evaluation of the predictor. The predictors were applied on the testing set, and the predicted outcomes were compared with actual outcomes in the testing set. 

All classification methods are based on assumption that both of the possible misclassification errors have equal importance.

```{r init classification, echo = FALSE}

titanicLogres <- titanic %>% dplyr::select(c("survived", varSet))
set.seed(127)

trRows <- createDataPartition(titanicLogres$survived, p = 0.8, list = F)
trData <- titanicLogres[trRows, ]
tstData <- titanicLogres[-trRows, ]

```

```{r logistic regression, echo = FALSE}

  glmFit <- glm(survived ~ ., data = trData, family = binomial(link = "logit"), na.action = na.exclude)
  trLogreg <- predict(glmFit, trData, type = "response")
  trLogreg <- ifelse(trLogreg  > 0.5, 1, 0)
  confTabTrLogreg <- table(trLogreg, as.integer(trData$survived))
  trAccur <- round(sum(diag(confTabTrLogreg)) / sum(confTabTrLogreg), 2)
  
  predLogreg <- predict(glmFit, tstData, type = "response")
  predLogreg <- ifelse(predLogreg  > 0.5, 1, 0)
  confTabLogreg <- table(predLogreg, as.integer(tstData$survived))  
  misRows <- which(is.na(predLogreg))
  if(length(misRows) > 0)
  {
    predLogreg <- predLogreg[-misRows]
    tstNomis <- tstData$survived[-misRows]
  }  

  ROClogreg <- prediction(predLogreg, tstNomis)
  perfROCplotLogreg <- performance(ROClogreg, "tpr", "fpr")

  perfROCLogreg <- performance(ROClogreg, "auc")
  accurRFLogreg <- perfROCLogreg@y.values[[1]]
  tstAccur <- round(sum(diag(confTabLogreg)) / sum(confTabLogreg), 2)
  
nullDev <- round(summary(glmFit)$null.deviance, 2)
resDev <- round(summary(glmFit)$deviance, 2) 
nullDf <- summary(glmFit)$df.null
resDf <- summary(glmFit)$df.residual
# pchisq(nullDev - resDev, df = nullDf- resDf, lower.tail = F)

ROClogreg <- prediction(predLogreg, tstNomis)
perfROCplotLogreg <- performance(ROClogreg, "tpr", "fpr")

perfROCLogreg <- performance(ROClogreg, "auc")
accurROCLogreg <- round(perfROCLogreg@y.values[[1]], 2)

```

### Logistic regression

The logistic regression can be directly applied for classification because the model contains only 2 outcomes. The optimal model obtained below contains `r length(varSet)` predictors: `r varSet`. The overall ratio of the testing correct prediction obtained from this method is `r tstAccur`, whereas the corresponding ratio of the training prediction is `r trAccur`. If such ratio of the training set is much higher than one for the testing set, it could indicate to overfitting. However, in our case the ratio of the testing correct prediction is even higher.

Two values indicating the fit quality of logistic regression are the null deviance corresponding to the model without predictors (the worse model) and the residual deviance corresponding to the model outlined above. Higher difference between these values (the first one is always larger due to presence of predictors) shows better fit. 

The next plot shows the ROC curve for the random forest predictor. The area under curve is `r accurROCLogreg`.

``` {r ROC LogregPlot, echo = FALSE}

plot(perfROCplotLogreg)
abline(a = 0, b = 1)

```
